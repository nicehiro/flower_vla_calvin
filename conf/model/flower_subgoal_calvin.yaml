# FlowerSubgoalVLA Configuration for CALVIN
# Extension of FLOWERVLA with proprio history injection and subgoal prediction head
_target_: flower.models.flower_subgoal.FlowerSubgoalVLA
_recursive_: false

# VLM Configuration
vlm_path: microsoft/Florence-2-large
freeze_florence: False
freeze_vision_tower: False
vlm_prompt_style: default
token_dropout: 0.1

# Model Structure
multistep: ${multistep}
num_sampling_steps: 4
lowdim_obs_dim: 7
action_dim: 7
act_window_size: 10

# Pretraining
load_pretrained: False
pretrained_model_path: null

# Model flags (inherited from FLOWERVLA)
use_second_view: True
second_view_key: image_wrist
action_type_adaln: True
use_causal_attention: true
use_cross_attn: True
use_adaln_cond: false
use_readout_token: false
use_proprio: false
return_act_chunk: false

# Proprio History Configuration
use_proprio_history: ${use_proprio_history}
proprio_history_len: ${proprio_history_len}
proprio_dims: ${proprio_dims}

# Subgoal Configuration
use_subgoal_head: ${use_subgoal_head}
subgoal_horizon: ${subgoal_horizon}
subgoal_interval: ${subgoal_interval}
subgoal_dit_dim: 1024
subgoal_n_layers: 12
subgoal_n_heads: 16

# Training Stage Configuration
training_stage: ${training_stage}
subgoal_loss_weight: ${subgoal_loss_weight}
action_loss_weight: ${action_loss_weight}

# DiT Configuration (Action Head)
sampling_type: uniform
dit_dim: 1024
n_heads: 16
n_layers: 18
attn_pdrop: 0.1
resid_pdrop: 0.1
mlp_pdrop: 0.1

# RoPE Configuration
use_rope: true
use_nope: false
query_seq_len: 100
rope_theta: 32.0

# Optimizer Configuration
optimizer_type: adamw

optimizer:
  _target_: torch.optim.AdamW
  transformer_weight_decay: 0.05
  learning_rate: 2e-5
  betas: [0.9, 0.95]

# Learning Rate Scheduler
lr_scheduler:
  lr_scheduler:
    init_lr: 2e-5
    init_lr_scale: 0.1
    final_lr_scale: 0.5
    total_steps: 50000
    phase_ratio: "(0.05, 0.1, 0.85)"
    lr: 2e-5
